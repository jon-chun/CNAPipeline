{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Sentences Relating to Ingroup and Outgroup\n",
    "\n",
    "In this notebook we iterate over all the sentence in the speech if appropriate manually classify each sentence as either ingroup elevation or outgroup othering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "import os\n",
    "\n",
    "# dictionary object for the sentences from each file\n",
    "sentences = dict()\n",
    "\n",
    "# iterate over sentences from each orator, remove any return symbols and add to dictionary object\n",
    "# note, sentences are identified by their index in a document rather than the word\n",
    "for sentence in doc.sents:\n",
    "    if doc[sentence.end -1].text == '\\n':\n",
    "        sentences[len(sentences)] = [sentence.start, sentence.end - 1]\n",
    "    else:\n",
    "        sentences[len(sentences)] = [sentence.start, sentence.end]\n",
    "    \n",
    "# print the first five sentences of each sentence dictionary\n",
    "i=0\n",
    "for key, value in sentences.items():\n",
    "    print(key, '=>', doc[value[0]:value[1]])\n",
    "    i+=1\n",
    "    if i == 5:\n",
    "        break\n",
    "print()\n",
    "\n",
    "ingroup = dict()\n",
    "outgroup = dict()\n",
    "index = dict()\n",
    "\n",
    "# open previous file and progress index\n",
    "\n",
    "filepath = 'C:/Users/Steve/OneDrive - University of Southampton/CulturalViolence/KnowledgeBases/'\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(filepath, \"ingroup_sentences.json\"), 'r') as fp:\n",
    "        ingroup = json.load(fp)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(filepath, \"outgroup_sentences.json\"), 'r') as fp:\n",
    "        outgroup = json.load(fp)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(filepath, \"index.json\"), 'r') as fp:\n",
    "        index = json.load(fp)\n",
    "except:\n",
    "    index[\"index\"] = 0\n",
    "\n",
    "\n",
    "print(index)\n",
    "\n",
    "#iterate over each sentence dictionary for classification of ingroup or outgroup\n",
    "while i < len(sentences):\n",
    "    # get the current progress through the dictionary object\n",
    "    i = index[\"index\"]\n",
    "    \n",
    "    # record progress  through dictionary object\n",
    "    with open(os.path.join(filepath, \"index.json\"), \"wb\") as f:\n",
    "            f.write(json.dumps(index).encode(\"utf-8\"))\n",
    "    \n",
    "    # print current sentence\n",
    "    print('-----')\n",
    "    print('index: ', i)\n",
    "    displacy.render(doc[sentences[i][0]:sentences[i][1]], style = 'ent')\n",
    "    print(i, '/', len(sentences), '=>', doc[sentences[i][0]:sentences[i][1]])\n",
    "    entry = input('ingroup(i) / outgroup(o) / back(b)').lower()\n",
    "    \n",
    "    # ask if sentence is refering to an ingroup or outgroup\n",
    "    if entry in ['i', 'o']:        \n",
    "        if entry == 'i': # add sentence to ingroup dictionary if user selects ingroup\n",
    "            print(len(ingroup), ' => ingroup add: ', doc[sentences[i][0]:sentences[i][1]])\n",
    "            ingroup[len(ingroup)] = [sentences[i][0], sentences[i][1]]\n",
    "            \n",
    "            # write dictionary to file\n",
    "            with open(os.path.join(filepath, \"ingroup_sentences.json\"), \"wb\") as f:\n",
    "                f.write(json.dumps(ingroup).encode(\"utf-8\"))\n",
    "            \n",
    "        else: # else add sentence to outgroup dictionary\n",
    "            print(len(outgroup), ' => outgroup add: ', doc[sentences[i][0]:sentences[i][1]])\n",
    "            outgroup[len(outgroup)] = [sentences[i][0], sentences[i][1]]\n",
    "            \n",
    "            # write dictionary to file\n",
    "            with open(os.path.join(filepath, \"outgroup_sentences.json\"), \"wb\") as f:\n",
    "                f.write(json.dumps(outgroup).encode(\"utf-8\"))\n",
    "                \n",
    "        # increase index by 1\n",
    "        index[\"index\"] += 1\n",
    "    \n",
    "    \n",
    "    # if user enters 'b' then go back by 1 in the dictionary and delete\n",
    "    elif entry == 'b': \n",
    "        if i != 0:\n",
    "            \n",
    "            # test whether the previous sentence was ingroup or outgroup and delete from respective dictionary\n",
    "            \n",
    "            if len(ingroup) - 1 >= 0 and sentences[i-1] == ingroup[len(ingroup) - 1]:\n",
    "                print('deleting from ingroup: ', doc[ingroup[len(ingroup) - 1][0]:ingroup[len(ingroup) - 1][1]])\n",
    "                del(ingroup[len(ingroup) - 1])\n",
    "\n",
    "                with open(os.path.join(filepath, \"ingroup_sentences.json\"), \"wb\") as f:\n",
    "                    f.write(json.dumps(ingroup).encode(\"utf-8\"))\n",
    "\n",
    "            elif len(outgroup) - 1 >= 0 and sentences[i-1] == outgroup[len(outgroup) - 1]:\n",
    "                print('deleting from outgroup: ', doc[outgroup[len(outgroup) - 1][0]:outgroup[len(outgroup) - 1][1]])\n",
    "                del(outgroup[len(outgroup) - 1])\n",
    "\n",
    "                with open(os.path.join(filepath, \"outgroup_sentences.json\"), \"wb\") as f:\n",
    "                    f.write(json.dumps(outgroup).encode(\"utf-8\"))\n",
    "\n",
    "            index[\"index\"] -= 1\n",
    "        \n",
    "        else:\n",
    "            print('iterating backwards by one sentence')\n",
    "            pass\n",
    "        \n",
    "    # quit    \n",
    "    elif entry == 'q':\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        index[\"index\"] += 1\n",
    "\n",
    "print(f'completed at {str(datetime.datetime.now())}') #1220"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
