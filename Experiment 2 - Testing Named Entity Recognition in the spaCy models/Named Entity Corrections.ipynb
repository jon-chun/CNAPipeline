{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Corrections\n",
    "\n",
    "In this notebook we test the named entity recognition in the spaCy language model.\n",
    "\n",
    "Each sentence in each document is reviewed by displaying the named entities in each.\n",
    "\n",
    "Any errors are noted and a report is produced.\n",
    "\n",
    "The errors are corrected with an custom pipeline component added to the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of doc:  220536\n",
      "completed at: Feb 11 2020 12:43:08\n",
      "Wall time: 224 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "FileList = ['20010114-Remarks at the National Day of Prayer & Remembrance Service.txt',\n",
    "            '20010115-First Radio Address following 911.txt',\n",
    "            '20010117-Address at Islamic Center of Washington, D.C..txt',\n",
    "           '20010120-Address to Joint Session of Congress Following 911 Attacks.txt',\n",
    "           '20010911-Address to the Nation.txt',\n",
    "           '20011007-Operation Enduring Freedom in Afghanistan Address to the Nation.txt',\n",
    "           '20011011-911 Pentagon Remembrance Address.txt',\n",
    "           '20011011-Prime Time News Conference on War on Terror.txt',\n",
    "           '20011026-Address on Signing the USA Patriot Act of 2001.txt',\n",
    "           '20011110-First Address to the United Nations General Assembly.txt',\n",
    "           '20011211-Address to Citadel Cadets.txt',\n",
    "           '20011211-The World Will Always Remember 911.txt',\n",
    "           '20020129-First (Official) Presidential State of the Union Address.txt',\n",
    "           ]\n",
    "raw = ''\n",
    "\n",
    "filepath = 'C:/Users/Steve/OneDrive - University of Southampton/CulturalViolence/KnowledgeBases/Speeches/'\n",
    "\n",
    "binladenpath = os.path.join(filepath, 'Osama bin Laden/')\n",
    "bushpath = os.path.join(filepath, 'George Bush/')\n",
    "\n",
    "for f in FileList:\n",
    "    with open(bushpath + f, 'r') as text:\n",
    "        raw = raw + text.read()\n",
    "\n",
    "FileList = ['19960823-OBL Declaration.txt',\n",
    "            '20011007-OBL Full Warning.txt',\n",
    "            '20011109-OBL.txt',\n",
    "            '20021124-OBL Letter to America.txt',\n",
    "            '20041101-Al Jazeera Speech.txt'\n",
    "           ]\n",
    "\n",
    "for f in FileList:\n",
    "    with open(binladenpath + f, 'r') as text:\n",
    "        raw = raw + text.read()\n",
    "        \n",
    "# with open(os.path.join(filepath, \"fulltext.txt\"), 'w') as text:\n",
    "#         text.write(raw)\n",
    "\n",
    "print('length of doc: ', len(raw))\n",
    "print(f'completed at: {datetime.datetime.now().strftime(\"%b %d %Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup spaCy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading:  en_core_web_md\n",
      "completed at: Feb 11 2020 12:43:28\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import spacy\n",
    "model = 'en_core_web_md'\n",
    "print('loading: ', model)\n",
    "nlp = spacy.load(model)\n",
    "\n",
    "print(f'completed at: {datetime.datetime.now().strftime(\"%b %d %Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Components\n",
      "tagger | parser | ner | entity_ruler | merge_entities\n",
      "processing doc\n",
      "doc processed\n",
      "current corrections\n",
      "['USAMA BIN MUHAMMAD BIN LADIN']\n",
      "['AHLUL-SUNNAH', 'INFIDEL', 'KUFFAR', 'KAFIROON', 'KAFEROON', 'MUSLIM', \"DA'EES\", 'ULAMA']\n",
      "['MAKKA', \"KA'BA\", 'CAPITOL', 'GUADALCANAL', 'THE WORLD TRADE CENTER', 'THE TREATY ROOM OF THE WHITE HOUSE']\n",
      "['BANI QURAYDAH', 'TALIBAN', 'AL QAEDA', 'EGYPTIAN ISLAMIC JIHAD', 'ISLAMIC MOVEMENT OF UZBEKISTAN', 'REPUBLICANS', 'DEMOCRATS', 'MAFIA', 'CRUSADERS', 'MUJAHIDEEN', 'HALLIBURTON', 'JAISH-I-MOHAMMED', 'UMMAH', 'QURAYSH', \"BANI QAINUQA'\"]\n",
      "['THE ARABIAN PENINSULA', 'THE LAND OF THE TWO HOLY PLACES', 'THE COUNTRY OF THE TWO HOLY PLACES', 'QANA', 'ASSAM', 'ERITHRIA', 'CHECHNIA', 'MAKKA', 'MAKKAH', 'QUNDUZ', 'MAZUR-E-SHARIF', 'RAFAH']\n",
      "['DAR AL-ISLAM', 'KABAL', 'IWO JIMA', 'GROUND ZERO', 'WORLD', 'DUNYA']\n",
      "['UNITED 93', 'GLOBAL HAWK', 'FLIGHT 93', 'PREDATOR']\n",
      "['NATIONAL ANTHEM', 'MEMORANDUM', 'FLAG', 'THE MARSHALL PLAN', 'SEMPER FI', 'ALLAHU AKBAR']\n",
      "['CONSTITUTION', 'ANTI-BALLISTIC MISSILE TREATY', 'THE TREATY OF HUDAYBIYYAH', 'KYOTO AGREEMENT']\n",
      "['SHAWWAAL', 'MUHARRAM', 'RASHIDOON']\n",
      "['RIYAL']\n",
      "['GULF WAR']\n",
      "['COLD WAR']\n",
      "['ISLAM', 'CHRISTIANITY']\n",
      "['HUBAL', 'GOD', 'LORD']\n",
      "['JESUS', 'ABRAHAM', 'JIBREEL', 'ISHMAEL', 'ISAAC', 'ALLAH', 'IMRAAN', 'HUD', 'AAL-IMRAAN', \"AL-MA'IDA\", 'BAQARAH', 'AN-NISA', 'AL-AHZAB', \"SHU'AIB\", \"AL'IZ IBN ABD ES-SALAAM\", 'IBN TAYMIYYAH', 'AN-NOOR', \"MAJMOO' AL FATAWA\", 'LUQMAN', 'AL-MASJID AN-NABAWY', 'ABD UR-RAHMAN IBN AWF', 'ABU JAHL', 'AAL IMRAAN', 'THE MESSENGER OF ALLAH', 'SAHEEH AL-JAME', 'AT-TIRMIDHI', 'AT-TAUBAH', 'HAROON AR-RASHEED', \"AMEER-UL-MU'MINEEN\", 'ASSIM BIN THABIT', 'THE PROPHET', 'MOSES']\n",
      "['HALAL', 'HARAM', \"SHARI'A\", 'MUSHRIK', 'FATWA', 'FATWAS', 'SHARIAH', \"SHARI'AH\"]\n",
      "['JIHAD', 'CRUSADE']\n",
      "['QURAN', 'AS-SAYF', 'TAGHUT', 'TORAH', 'PSALM', 'QIBLAH', 'ALLAHU AKBAR']\n",
      "['JANNAH']\n",
      "[\"KAA'BA\"]\n",
      "completed at: Feb 11 2020 12:49:30\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Doc\n",
    "from spacy.tokens import Span\n",
    "from spacy.pipeline import merge_noun_chunks\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "# setup object to store entity corrections, which in turn forms the basis for the custom pipeline component.\n",
    "named_entity_corrections = {\n",
    "    \n",
    "    # inbuilt with spaCy\n",
    "    \"PERSON\" : [\"usama bin muhammad bin ladin\"],\n",
    "    \"NORP\" : [\"ahlul-sunnah\", \"infidel\", \"kuffar\", \"kafiroon\", \"kaferoon\", \"muslim\", \"da'ees\", \"ulama\"],\n",
    "    \"FAC\"  : [\"makka\", \"ka'ba\", \"capitol\", \"guadalcanal\", \"the world trade center\", \\\n",
    "              \"the treaty room of the white house\"],\n",
    "    \"ORG\" : [\"bani quraydah\", \"taliban\", \"al qaeda\", \"egyptian islamic jihad\", \"islamic movement of uzbekistan\", \\\n",
    "            \"republicans\", \"democrats\", \"mafia\", \"crusaders\", \"mujahideen\", \"halliburton\", \"jaish-i-mohammed\", \\\n",
    "            \"ummah\", \"quraysh\", \"bani qainuqa'\"],\n",
    "    \"GPE\" : [\"the arabian peninsula\", \"the land of the two holy places\", \"the country of the two holy places\", \"qana\", \"assam\", \\\n",
    "            \"erithria\", \"chechnia\", \"makka\", \"makkah\", \"qunduz\", \"mazur-e-sharif\", \"rafah\"],\n",
    "    \"LOC\" : [\"dar al-islam\", \"kabal\", \"iwo jima\", \"ground zero\", \"world\", \"dunya\"],\n",
    "    \"PRODUCT\" : [\"united 93\", \"global hawk\", \"flight 93\", \"predator\"],\n",
    "    \"EVENT\" : [],\n",
    "    \"WORK_OF_ART\" : [\"national anthem\", \"memorandum\", \"flag\", \"the marshall plan\", \"semper fi\", \"allahu akbar\"],\n",
    "    \"LAW\" : [\"constitution\", \"anti-ballistic missile treaty\", \"the treaty of hudaybiyyah\", \"kyoto agreement\"],\n",
    "    \"LANGUAGE\" : [],\n",
    "    \"DATE\" : [\"shawwaal\", \"muharram\", \"rashidoon\"],\n",
    "    \"TIME\" : [],\n",
    "    \"PERCENT\" : [],\n",
    "    \"MONEY\" : [\"riyal\"],\n",
    "    \"QUANTITY\" : [],\n",
    "    \"ORDINAL\" : [],\n",
    "    \"CARDINAL\" : [],\n",
    "    \n",
    "    ##user defined\n",
    "    \"DIRECTVIOLENCE\" : [\"gulf war\"],\n",
    "    \"STRUCTURALVIOLENCE\" : [\"cold war\"],\n",
    "    \"RELIGION\" : [\"islam\", \"christianity\"],\n",
    "    \"DEITY\" : [\"hubal\", \"god\", \"Lord\"],\n",
    "    \"RELIGIOUSFIGURE\" : [\"jesus\", \"abraham\", \"jibreel\", \"ishmael\", \"isaac\", \"allah\", \"imraan\", \"hud\", \"aal-imraan\", \"al-ma'ida\", \\\n",
    "                         \"baqarah\", \"an-nisa\", \"al-ahzab\", \"shu'aib\", \"al'iz ibn abd es-salaam\", \\\n",
    "                        \"ibn taymiyyah\", \"an-noor\", \"majmoo' al fatawa\", \"luqman\", \"al-masjid an-nabawy\", \\\n",
    "                        \"abd ur-rahman ibn awf\", \"abu jahl\", \"aal imraan\", \"the messenger of allah\", \\\n",
    "                        \"Saheeh Al-Jame\", \"at-tirmidhi\", \"at-taubah\", \"haroon ar-rasheed\", \"ameer-ul-mu'mineen\", \\\n",
    "                        \"assim bin thabit\", \"the prophet\", \"moses\"],\n",
    "    \"RELIGIOUSLAW\" : [\"halal\", \"haram\", \"shari'a\", \"mushrik\", \"fatwa\", \"fatwas\", \"shariah\", \"shari'ah\"],\n",
    "    \"RELIGIOUSCONFLICT\" : [\"jihad\", \"crusade\"],\n",
    "    \"RELIGIOUS_WORK_OF_ART\" : [\"quran\", \"as-sayf\", \"taghut\", \"torah\", \"psalm\", \"qiblah\", \"allahu akbar\"],\n",
    "    \"RELIGIOUSENTITY\" : [\"jannah\"],\n",
    "    \"RELIGIOUS_FAC\" : [\"kaa'ba\"],\n",
    "}\n",
    "\n",
    "filepath = \"C:/Users/Steve/OneDrive - University of Southampton/CulturalViolence/KnowledgeBases/Experiment 2 - Testing Named Entity Recognition in the spaCy models/\"\n",
    "\n",
    "## create file to store entity corrections\n",
    "with open(os.path.join(filepath, \"named_entity_corrections.json\"), \"wb\") as f:\n",
    "    f.write(json.dumps(named_entity_corrections).encode(\"utf-8\"))                         \n",
    "\n",
    "# create entity ruler for custom pipeline component\n",
    "entities = EntityRuler(nlp, overwrite_ents=True, phrase_matcher_attr = \"LOWER\")\n",
    "\n",
    "for key, value in named_entity_corrections.items():\n",
    "    pattern = {\"label\" : key, \"pattern\" : [{\"LOWER\" : {\"IN\" : value}}]}, #, \"POS\" : {\"IN\": [\"PROPN\", \"NOUN\"]}\n",
    "    entities.add_patterns(pattern)\n",
    "\n",
    "# modify spaCy pipeline with custom component\n",
    "    \n",
    "import json\n",
    "from spacy.pipeline import merge_entities\n",
    "from spacy.strings import StringStore\n",
    "\n",
    "for pipe in nlp.pipe_names:\n",
    "    if pipe not in ['tagger', \"parser\", \"ner\"]:\n",
    "        nlp.remove_pipe(pipe)\n",
    "        \n",
    "for key in named_entity_corrections.keys():\n",
    "    nlp.vocab.strings.add(key)\n",
    "        \n",
    "nlp.add_pipe(entities, after = \"ner\")\n",
    "# nlp.add_pipe(ent_matcher, before = \"ner\")\n",
    "nlp.add_pipe(merge_entities, last = True)\n",
    "#nlp.add_pipe(merge_noun_chunks, last = True)\n",
    "\n",
    "print(\"Pipeline Components\")\n",
    "print(' | '.join(nlp.pipe_names))\n",
    "\n",
    "print(\"processing doc\")\n",
    "doc = nlp(raw)\n",
    "print(\"doc processed\")\n",
    "\n",
    "print(\"current corrections\")\n",
    "#print out the corrections\n",
    "for label, terms in named_entity_corrections.items():\n",
    "    if len(terms) > 0:\n",
    "        patterns = [text.upper() for text in terms]\n",
    "        print(patterns)\n",
    "        \n",
    "#         patterns = [nlp.make_doc(text) for text in pattern[\"pattern\"]] # -- used for PhraseMatcher\n",
    "#         self.matcher.add(pattern[\"label\"], None, *patterns)\n",
    "\n",
    "print(f'completed at: {datetime.datetime.now().strftime(\"%b %d %Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Each Sentence to Check for Corrections\n",
    "\n",
    "Iterate through each sentence to review the named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e55fc3e2cfc7451f80c5bd5a2ee921e1-0\" class=\"displacy\" width=\"1975\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">On</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Tuesday,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">our</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">country</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">attacked</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">deliberate</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">massive</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">cruelty.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,2.0 925.0,2.0 925.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-1\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M205.0,441.5 L213.0,429.5 197.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-2\" stroke-width=\"2px\" d=\"M420,439.5 C420,352.0 555.0,352.0 555.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,441.5 L412,429.5 428,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,264.5 910.0,264.5 910.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-4\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-5\" stroke-width=\"2px\" d=\"M945,439.5 C945,352.0 1080.0,352.0 1080.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1080.0,441.5 L1088.0,429.5 1072.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-6\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,177.0 1790.0,177.0 1790.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-7\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1430.0,441.5 L1438.0,429.5 1422.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-8\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,264.5 1610.0,264.5 1610.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610.0,441.5 L1618.0,429.5 1602.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-9\" stroke-width=\"2px\" d=\"M1120,439.5 C1120,89.5 1795.0,89.5 1795.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e55fc3e2cfc7451f80c5bd5a2ee921e1-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1795.0,441.5 L1803.0,429.5 1787.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">On \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", our country was attacked with deliberate and massive cruelty. </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>On</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>,</td>\n",
       "      <td>our</td>\n",
       "      <td>country</td>\n",
       "      <td>was</td>\n",
       "      <td>attacked</td>\n",
       "      <td>with</td>\n",
       "      <td>deliberate</td>\n",
       "      <td>and</td>\n",
       "      <td>massive</td>\n",
       "      <td>cruelty</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEMMA</th>\n",
       "      <td>on</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>,</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>country</td>\n",
       "      <td>be</td>\n",
       "      <td>attack</td>\n",
       "      <td>with</td>\n",
       "      <td>deliberate</td>\n",
       "      <td>and</td>\n",
       "      <td>massive</td>\n",
       "      <td>cruelty</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAG</th>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>,</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>JJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEP</th>\n",
       "      <td>prep</td>\n",
       "      <td>pobj</td>\n",
       "      <td>punct</td>\n",
       "      <td>poss</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>auxpass</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>prep</td>\n",
       "      <td>amod</td>\n",
       "      <td>cc</td>\n",
       "      <td>conj</td>\n",
       "      <td>pobj</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENT_TYPE</th>\n",
       "      <td></td>\n",
       "      <td>DATE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1      2       3          4        5         6     7           8      9       10       11     12\n",
       "index        0        1      2       3          4        5         6     7           8      9       10       11     12\n",
       "sentence    On  Tuesday      ,     our    country      was  attacked  with  deliberate    and  massive  cruelty      .\n",
       "POS        ADP    PROPN  PUNCT     DET       NOUN     VERB      VERB   ADP         ADJ  CCONJ      ADJ     NOUN  PUNCT\n",
       "LEMMA       on  Tuesday      ,  -PRON-    country       be    attack  with  deliberate    and  massive  cruelty      .\n",
       "TAG         IN      NNP      ,    PRP$         NN      VBD       VBN    IN          JJ     CC       JJ       NN      .\n",
       "DEP       prep     pobj  punct    poss  nsubjpass  auxpass      ROOT  prep        amod     cc     conj     pobj  punct\n",
       "ENT_TYPE           DATE                                                                                               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 3 / 2164 )\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "continue n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed at: Feb 11 2020 12:54:20\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sentences = dict()\n",
    "index = dict()\n",
    "\n",
    "filepath = \"C:/Users/Steve/OneDrive - University of Southampton/CulturalViolence/KnowledgeBases/dataindex.json\"\n",
    "\n",
    "# iterate over each sentence in a document to create a dictionary object containing all the sentences.\n",
    "for i, sentence in enumerate(doc.sents):\n",
    "    sentences[i] = sentence\n",
    "    \n",
    "# the index file stores the progress from a previous session\n",
    "try:\n",
    "    with open(filepath, 'r') as fp:\n",
    "        index = json.load(fp)\n",
    "        if index[\"index\"] <= 2: # if the index is empty then reset\n",
    "            index[\"index\"] = 0\n",
    "        else:\n",
    "            index[\"index\"] -= 2 # if the index is not empty then go back by two sentences\n",
    "except:\n",
    "    index[\"index\"] = 0 # if the file does not exist, then reset index to 0\n",
    "    pass\n",
    "\n",
    "# iterate over the sentences in the dictionary object\n",
    "while i < len(sentences):\n",
    "    i = index[\"index\"]\n",
    "    \n",
    "    # write the current index to file.\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        f.write(json.dumps(index).encode(\"utf-8\"))\n",
    "        \n",
    "    # display the dependency parse\n",
    "    displacy.render(doc[sentences[i].start].sent, style = \"dep\")\n",
    "    print('-----')\n",
    "    # display the entity recognition\n",
    "    options = {\"compact\": True}\n",
    "    displacy.render(doc[sentences[i].start].sent, style = \"ent\", options = options)\n",
    "    \n",
    "    # display the attributes for each word in the sentence\n",
    "    \n",
    "    idx = []\n",
    "    word_list = []\n",
    "    lemma_list = []\n",
    "    pos_list = []\n",
    "    tag_list = []\n",
    "    dep_list = []\n",
    "    ent_type_list = []\n",
    "    \n",
    "    #if not {\"we\", \"us\", \"our\"}.isdisjoint(set(map(lambda tok: tok.lower_, sentence))):\n",
    "    #if 'OUTGROUP' in set(map(lambda tok: tok.lower, sentence)):\n",
    "    for n, word in enumerate(doc[sentences[i].start].sent):\n",
    "        idx.append(n)\n",
    "        word_list.append(word.text)\n",
    "        lemma_list.append(word.lemma_)\n",
    "        pos_list.append(word.pos_)\n",
    "        tag_list.append(word.tag_)\n",
    "        dep_list.append(word.dep_)\n",
    "        ent_type_list.append(word.ent_type_)\n",
    "\n",
    "    sent_dict = {'index' : idx,\n",
    "                   'sentence' : word_list,\n",
    "                   'POS' : pos_list,\n",
    "                   'LEMMA' : lemma_list,\n",
    "                   'TAG' : tag_list,\n",
    "                   'DEP' : dep_list,\n",
    "                   'ENT_TYPE' : ent_type_list,\n",
    "                      }\n",
    "    \n",
    "    pd.set_option(\"expand_frame_repr\", False)\n",
    "    pd.set_option(\"display.max_columns\", 999)\n",
    "    display(pd.DataFrame.from_dict(sent_dict).T)\n",
    "    \n",
    "    print('(', i, '/', len(sentences), ')')\n",
    "    val = input(\"continue\")\n",
    "    if val in ['n', 'q']: # if the user inputs 'n' or 'q', then bread\n",
    "        break\n",
    "    elif val == 'b': # if the user inputs 'b' go back by one - allows changes to be made in hindsight\n",
    "        index[\"index\"] -= 1\n",
    "        clear_output()\n",
    "        continue\n",
    "    else:\n",
    "        index[\"index\"] += 1 # else move the index forward by 1 to progress through the dictionary object.\n",
    "        clear_output()\n",
    "        continue\n",
    "        \n",
    "print(f'completed at: {datetime.datetime.now().strftime(\"%b %d %Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PDF Report for Each Orator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from weasyprint import HTML\n",
    "\n",
    "filepath = \"C:/Users/Steve/OneDrive - University of Southampton/CulturalViolence/KnowledgeBases/Experiment 2 - Testing Named Entity Recognition in the spaCy models/\"\n",
    "\n",
    "with open(os.path.join(filepath, \"binladen_entitycorrections.json\"), 'r') as fp:\n",
    "    questions = json.load(fp)\n",
    "\n",
    "env = Environment(loader=FileSystemLoader(searchpath=filepath))\n",
    "template = env.get_template('myreport.html')\n",
    "  \n",
    "table = pd.DataFrame.from_dict(questions).T\n",
    "\n",
    "template_vars = {\"title\" : \"bin Laden Entity Corrections\",\n",
    "                 \"islamic_terms\": table.to_html()}\n",
    "    \n",
    "html_out = template.render(template_vars)\n",
    "HTML(string=html_out).write_pdf(os.path.join(filepath, \"binladen_entitycorrections.pdf\"), stylesheets=[os.path.join(filepath, \"style.css\")])    \n",
    "    \n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.set_option(\"display.max_columns\", 999)\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "    \n",
    "display(pd.DataFrame.from_dict(questions).T\n",
    "        .style.set_properties(**{'text-align': 'left'})\n",
    "        .set_table_styles([dict(selector='th', props=[('text-align', 'left')])]))\n",
    "\n",
    "print(f'completed at {str(datetime.datetime.now())}') #1220"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
