{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Benchmark Data\n",
    "---\n",
    " \n",
    "In this notebook the benchmark data is creating for testing the NLP technologies in each experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InGroup and Outgroup For Each Orator\n",
    "\n",
    "In this cell a JSON object is created containing the ingroups and outgroups of each orator. These groups are noun phrases identifying the groups and are taken from the speech in which each orator identified their outgroup. For bin Laden, this was his first speech published on 23/08/1996; for Bush he first identified hi outgroup in his State of the Union address on 20/09/2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete at:  24/02/2020 - 15:40:04\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "groups_benchmark = {\n",
    "    \n",
    "    \"bush\" : {\n",
    "        \"ingroup\" : [\"america\", \"american people\", \"americans\", \"united states\", \"united states of America\", \"my fellow americans\", \"fellow americans\"],\n",
    "        \"outgroup\" : [\"al qaeda\", \"taliban regime\", \"taliban\", \"egyptian islamic jihad\", \"islamic movement of uzbekistan\"]\n",
    "    },\n",
    "    \n",
    "    \"binladen\" : {\n",
    "        \"ingroup\" : [\"people of islam\", \"islamic world\", \"ummah of islam\", \"muslims\", \"muslim people\", \"muslim nation\"],\n",
    "        \"outgroup\" : [\"zionist-crusaders alliance\", \"american crusaders\", \"american zionist alliance\", \"american-israeli alliance\", \"saudi regime\", \"american enemy\", \"zionist-crusaders\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "filepath = \"C:/Users/Steve/OneDrive - University of Southampton/CulturalViolence/KnowledgeBases/Data/\"\n",
    "\n",
    "with open(os.path.join(filepath, \"groups_benchmark.json\"), \"wb\") as f:\n",
    "    f.write(json.dumps(groups_benchmark).encode(\"utf-8\"))\n",
    "    \n",
    "print(\"complete at: \", datetime.now().strftime(\"%d/%m/%Y - %H:%M:%S\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bush', 'binladen']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ingroup</th>\n",
       "      <th>outgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">bush</th>\n",
       "      <th>0</th>\n",
       "      <td>america</td>\n",
       "      <td>al qaeda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american people</td>\n",
       "      <td>taliban regime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>americans</td>\n",
       "      <td>taliban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>united states</td>\n",
       "      <td>egyptian islamic jihad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united states of America</td>\n",
       "      <td>islamic movement of uzbekistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>my fellow americans</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fellow americans</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">binladen</th>\n",
       "      <th>0</th>\n",
       "      <td>people of islam</td>\n",
       "      <td>zionist-crusaders alliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>islamic world</td>\n",
       "      <td>american crusaders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ummah of islam</td>\n",
       "      <td>american zionist alliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muslims</td>\n",
       "      <td>american-israeli alliance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>muslim people</td>\n",
       "      <td>saudi regime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim nation</td>\n",
       "      <td>american enemy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>zionist-crusaders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ingroup                        outgroup\n",
       "bush     0                   america                        al qaeda\n",
       "         1           american people                  taliban regime\n",
       "         2                 americans                         taliban\n",
       "         3             united states          egyptian islamic jihad\n",
       "         4  united states of America  islamic movement of uzbekistan\n",
       "         5       my fellow americans                                \n",
       "         6          fellow americans                                \n",
       "binladen 0           people of islam      zionist-crusaders alliance\n",
       "         1             islamic world              american crusaders\n",
       "         2            ummah of islam       american zionist alliance\n",
       "         3                   muslims       american-israeli alliance\n",
       "         4             muslim people                    saudi regime\n",
       "         5             muslim nation                  american enemy\n",
       "         6                                         zionist-crusaders"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/19736080/creating-dataframe-from-a-dictionary-where-entries-have-different-lengths\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "keys = list(groups_benchmark.keys())\n",
    "print(keys)\n",
    "\n",
    "frames = []\n",
    "for value in groups_benchmark.values():\n",
    "    frames.append(pd.DataFrame(dict([ (k, pd.Series(v)) for k, v in value.items() ]), index = None).fillna(\"\"))\n",
    "\n",
    "display(pd.concat(frames , keys = keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "FileList = ['20010114-Remarks at the National Day of Prayer & Remembrance Service.txt',\n",
    "            '20010115-First Radio Address following 911.txt',\n",
    "            '20010117-Address at Islamic Center of Washington, D.C..txt',\n",
    "           '20010120-Address to Joint Session of Congress Following 911 Attacks.txt',\n",
    "           '20010911-Address to the Nation.txt',\n",
    "           '20011007-Operation Enduring Freedom in Afghanistan Address to the Nation.txt',\n",
    "           '20011011-911 Pentagon Remembrance Address.txt',\n",
    "           '20011011-Prime Time News Conference on War on Terror.txt',\n",
    "           '20011026-Address on Signing the USA Patriot Act of 2001.txt',\n",
    "           '20011110-First Address to the United Nations General Assembly.txt',\n",
    "           '20011211-Address to Citadel Cadets.txt',\n",
    "           '20011211-The World Will Always Remember 911.txt',\n",
    "           '20020129-First (Official) Presidential State of the Union Address.txt',\n",
    "           ]\n",
    "raw = ''\n",
    "\n",
    "filepath = 'C:/Users/Steve/OneDrive - University of Southampton/CulturalViolence/KnowledgeBases/Speeches/'\n",
    "\n",
    "binladenpath = os.path.join(filepath, 'Osama bin Laden/')\n",
    "bushpath = os.path.join(filepath, 'George Bush/')\n",
    "\n",
    "for f in FileList:\n",
    "    with open(bushpath + f, 'r') as text:\n",
    "        bushraw = bushraw + text.read()\n",
    "\n",
    "FileList = ['19960823-OBL Declaration.txt',\n",
    "            '20011007-OBL Full Warning.txt',\n",
    "            '20011109-OBL.txt',\n",
    "            '20021124-OBL Letter to America.txt',\n",
    "            '20041101-Al Jazeera Speech.txt'\n",
    "           ]\n",
    "\n",
    "for f in FileList:\n",
    "    with open(binladenpath + f, 'r') as text:\n",
    "        binladenraw = binladenraw + text.read()\n",
    "        \n",
    "# with open(os.path.join(filepath, \"fulltext.txt\"), 'w') as text:\n",
    "#         text.write(raw)\n",
    "\n",
    "print('length of doc: ', len(raw))\n",
    "print(f'completed at: {datetime.datetime.now().strftime(\"%b %d %Y %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Sentences Relating to Ingroup and Outgroup\n",
    "\n",
    "In this notebook we iterate over all the sentence in the speech if appropriate manually classify each sentence as either ingroup elevation or outgroup othering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "import os\n",
    "\n",
    "# dictionary object for the sentences from each file\n",
    "sentences = dict()\n",
    "\n",
    "# iterate over sentences from each orator, remove any return symbols and add to dictionary object\n",
    "# note, sentences are identified by their index in a document rather than the word\n",
    "for sentence in doc.sents:\n",
    "    if doc[sentence.end -1].text == '\\n':\n",
    "        sentences[len(sentences)] = [sentence.start, sentence.end - 1]\n",
    "    else:\n",
    "        sentences[len(sentences)] = [sentence.start, sentence.end]\n",
    "    \n",
    "# print the first five sentences of each sentence dictionary\n",
    "i=0\n",
    "for key, value in sentences.items():\n",
    "    print(key, '=>', doc[value[0]:value[1]])\n",
    "    i+=1\n",
    "    if i == 5:\n",
    "        break\n",
    "print()\n",
    "\n",
    "ingroup = dict()\n",
    "outgroup = dict()\n",
    "index = dict()\n",
    "\n",
    "# open previous file and progress index\n",
    "\n",
    "filepath = 'C:/Users/Steve/OneDrive - University of Southampton/CulturalViolence/KnowledgeBases/'\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(filepath, \"ingroup_sentences.json\"), 'r') as fp:\n",
    "        ingroup = json.load(fp)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(filepath, \"outgroup_sentences.json\"), 'r') as fp:\n",
    "        outgroup = json.load(fp)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    with open(os.path.join(filepath, \"index.json\"), 'r') as fp:\n",
    "        index = json.load(fp)\n",
    "except:\n",
    "    index[\"index\"] = 0\n",
    "\n",
    "\n",
    "print(index)\n",
    "\n",
    "#iterate over each sentence dictionary for classification of ingroup or outgroup\n",
    "while i < len(sentences):\n",
    "    # get the current progress through the dictionary object\n",
    "    i = index[\"index\"]\n",
    "    \n",
    "    # record progress  through dictionary object\n",
    "    with open(os.path.join(filepath, \"index.json\"), \"wb\") as f:\n",
    "            f.write(json.dumps(index).encode(\"utf-8\"))\n",
    "    \n",
    "    # print current sentence\n",
    "    print('-----')\n",
    "    print('index: ', i)\n",
    "    displacy.render(doc[sentences[i][0]:sentences[i][1]], style = 'ent')\n",
    "    print(i, '/', len(sentences), '=>', doc[sentences[i][0]:sentences[i][1]])\n",
    "    entry = input('ingroup(i) / outgroup(o) / back(b)').lower()\n",
    "    \n",
    "    # ask if sentence is refering to an ingroup or outgroup\n",
    "    if entry in ['i', 'o']:        \n",
    "        if entry == 'i': # add sentence to ingroup dictionary if user selects ingroup\n",
    "            print(len(ingroup), ' => ingroup add: ', doc[sentences[i][0]:sentences[i][1]])\n",
    "            ingroup[len(ingroup)] = [sentences[i][0], sentences[i][1]]\n",
    "            \n",
    "            # write dictionary to file\n",
    "            with open(os.path.join(filepath, \"ingroup_sentences.json\"), \"wb\") as f:\n",
    "                f.write(json.dumps(ingroup).encode(\"utf-8\"))\n",
    "            \n",
    "        else: # else add sentence to outgroup dictionary\n",
    "            print(len(outgroup), ' => outgroup add: ', doc[sentences[i][0]:sentences[i][1]])\n",
    "            outgroup[len(outgroup)] = [sentences[i][0], sentences[i][1]]\n",
    "            \n",
    "            # write dictionary to file\n",
    "            with open(os.path.join(filepath, \"outgroup_sentences.json\"), \"wb\") as f:\n",
    "                f.write(json.dumps(outgroup).encode(\"utf-8\"))\n",
    "                \n",
    "        # increase index by 1\n",
    "        index[\"index\"] += 1\n",
    "    \n",
    "    \n",
    "    # if user enters 'b' then go back by 1 in the dictionary and delete\n",
    "    elif entry == 'b': \n",
    "        if i != 0:\n",
    "            \n",
    "            # test whether the previous sentence was ingroup or outgroup and delete from respective dictionary\n",
    "            \n",
    "            if len(ingroup) - 1 >= 0 and sentences[i-1] == ingroup[len(ingroup) - 1]:\n",
    "                print('deleting from ingroup: ', doc[ingroup[len(ingroup) - 1][0]:ingroup[len(ingroup) - 1][1]])\n",
    "                del(ingroup[len(ingroup) - 1])\n",
    "\n",
    "                with open(os.path.join(filepath, \"ingroup_sentences.json\"), \"wb\") as f:\n",
    "                    f.write(json.dumps(ingroup).encode(\"utf-8\"))\n",
    "\n",
    "            elif len(outgroup) - 1 >= 0 and sentences[i-1] == outgroup[len(outgroup) - 1]:\n",
    "                print('deleting from outgroup: ', doc[outgroup[len(outgroup) - 1][0]:outgroup[len(outgroup) - 1][1]])\n",
    "                del(outgroup[len(outgroup) - 1])\n",
    "\n",
    "                with open(os.path.join(filepath, \"outgroup_sentences.json\"), \"wb\") as f:\n",
    "                    f.write(json.dumps(outgroup).encode(\"utf-8\"))\n",
    "\n",
    "            index[\"index\"] -= 1\n",
    "        \n",
    "        else:\n",
    "            print('iterating backwards by one sentence')\n",
    "            pass\n",
    "        \n",
    "    # quit    \n",
    "    elif entry == 'q':\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        index[\"index\"] += 1\n",
    "\n",
    "print(f'completed at {str(datetime.datetime.now())}') #1220"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
